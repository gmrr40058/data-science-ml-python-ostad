{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76417881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa68e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edeaf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1947f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train : np.ndarray    #Variable type defination\n",
    "X_test: np.ndarray    #Variable type defination\n",
    "y_train : np.ndarray    #Variable type defination\n",
    "y_test : np.ndarray    #Variable type defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50494d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d8c55e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be40cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x272834dca50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cf628dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12b0394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "270ed070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4004c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0a845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79751314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G M RIFAT REZA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(10, input_shape=(784,),\n",
    "                                             activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95026b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50b388bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.4703\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.3039\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2833\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2734\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x272f6de67b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train, epochs =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "540119c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2714829742908478, 0.9239000082015991]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb688eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    }
   ],
   "source": [
    "temp = model.predict(X_test_flattened[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81b2a4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5770055e-02, 4.5264113e-07, 4.9728550e-02, 9.6021086e-01,\n",
       "        2.2873755e-03, 9.6470028e-02, 1.1758975e-06, 9.9967664e-01,\n",
       "        7.3815078e-02, 5.9752500e-01]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7615686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.99967664)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f998df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6529dfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2340ced",
   "metadata": {},
   "source": [
    "#### Using headen layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96ad8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G M RIFAT REZA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2743\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1249\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.0867\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0661\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x272a1324190>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_h.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "model_h.fit(X_train_flattened, y_train, epochs =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64c373a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08193107694387436, 0.975600004196167]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "958a3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G M RIFAT REZA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2729\n",
      "Epoch 2/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1246\n",
      "Epoch 3/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9738 - loss: 0.0873\n",
      "Epoch 4/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0676\n",
      "Epoch 5/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0522\n",
      "Epoch 6/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0417\n",
      "Epoch 7/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0343\n",
      "Epoch 8/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0280\n",
      "Epoch 9/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0227\n",
      "Epoch 10/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0203\n",
      "Epoch 11/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0168\n",
      "Epoch 12/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0137\n",
      "Epoch 13/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0120\n",
      "Epoch 14/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0104\n",
      "Epoch 15/15\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x272a1325590>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_h.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "model_h.fit(X_train_flattened, y_train, epochs =15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30ea8a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2779\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1244\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0862\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0661\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0517\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0410\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0336\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0281\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0226\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0201\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0164\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0145\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0131\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0098\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0095\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0090\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0065\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0067\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x272a130c8a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_h = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_h.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "model_h.fit(X_train_flattened, y_train, epochs =20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
